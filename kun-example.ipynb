{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "from kunlib import KUNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Kernel(nn.Module):\n",
    "    def __init__(self, input_dim, input_len, \n",
    "                 output_dim, output_len, params={}):\n",
    "        super(Kernel, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_len = input_len\n",
    "        self.output_dim = output_dim\n",
    "        self.output_len = output_len \n",
    "        self.params = params \n",
    "\n",
    "        self.is_in_encoder = False #input_len >= output_len\n",
    "        self.is_in_decoder = False #input_len >= output_len\n",
    "\n",
    "    def update_params(self, params):\n",
    "        # Iterate over all fields in the class and update if they exist in params\n",
    "        self.params = params \n",
    "        for key, value in params.items():\n",
    "            setattr(self, key, value)  # Set the attribute from params\n",
    "    \n",
    "class KernelWrapper(nn.Module):\n",
    "    def __init__(self, kernel, input_dim, input_len, \n",
    "                 output_dim=1, output_len=1, \n",
    "                 kernel_hidden_layer=1,  \n",
    "                 params={},verbose=False):\n",
    "        super(KernelWrapper, self).__init__()\n",
    "\n",
    "        # kernel : kernel(input_dim, input_len, output_dim, output_len)\n",
    "        assert (issubclass(kernel, Kernel) or issubclass(kernel, nn.Module))\n",
    "        if isinstance(kernel, nn.Module) : \n",
    "          print(f\"kernel {kernel} heiritated nn.Module may not adapt.\")\n",
    "\n",
    "        self.input_dim, self.input_len, self.output_dim, self.output_len = \\\n",
    "                        input_dim, input_len, output_dim, output_len\n",
    "        self.verbose = verbose\n",
    "        self.unet_skip_concat = False\n",
    "        self.unet_skip = False\n",
    "        self.transpose = False\n",
    "        params[\"kernel_hidden_layer\"] = kernel_hidden_layer\n",
    "        \n",
    "        update_params(self, params)\n",
    "\n",
    "        self.hidden_size_list = []\n",
    "\n",
    "        if issubclass(kernel, Kernel):\n",
    "            print(\"kernel \", kernel, \"is a Kernel\")\n",
    "            self.kernel = kernel(input_dim, input_len, output_dim, output_len, params=params)\n",
    "        elif issubclass(kernel, nn.Linear):\n",
    "            print(\"kernel \", kernel, \"is a nn.Linear Kernel\")\n",
    "            self.kernel = kernel(input_dim*input_len, output_dim*output_len)\n",
    "        else:\n",
    "            assert False, f\"kernel {kernel} is not recognized\"\n",
    "            \n",
    "        self._unet_skip_output = None\n",
    "        self._unet_skip_input = None\n",
    "\n",
    "\n",
    "    def f(self, x):\n",
    "        if self.verbose : \n",
    "          print(\"---KernelWrapper.f(x) Input x.shape: \", x.shape)\n",
    "        x = self.kernel(x)\n",
    "        if self.verbose : \n",
    "          print(\"---KernelWrapper.f(x) Output x.shape: \", x.shape)\n",
    "        return x\n",
    "\n",
    "    def forward(self, x, train=False):\n",
    "        if self.verbose : \n",
    "          print(\"---KernelWrapper.forward(x) Input x.shape:\", x.shape)\n",
    "          print(\"---train:\", train)\n",
    "          if self._unet_skip_input is not None:\n",
    "              print(\"---_unet_skip_input.shape\", self._unet_skip_input.shape)\n",
    "          else:\n",
    "              print(\"---_unet_skip_input\", self._unet_skip_input)\n",
    "\n",
    "        if self.transpose and self._unet_skip_input is not None:\n",
    "            if self.verbose : \n",
    "                print(\"self.transpose and self._unet_skip_input\")\n",
    "                print(\"--x.shape\", x.shape)\n",
    "            if np.prod(x.shape) == np.prod(self._unet_skip_input.shape):\n",
    "                if self.verbose : \n",
    "                    print(\"self.unet_skip_concat, x.shape\", self.unet_skip_concat, x.shape)\n",
    "                if self.unet_skip_concat:\n",
    "                    x = torch.cat([x, self._unet_skip_input.reshape(x.shape)], dim=-1)\n",
    "                    #print( \"after, \", self.unet_skip_concat, x.shape)\n",
    "                else:\n",
    "                    x = x + self._unet_skip_input.reshape(x.shape)\n",
    "                #print(\"_unet_skip_input.shape\", self._unet_skip_input.shape)\n",
    "            #x[len(self._unet_skip_input):] = x[len(self._unet_skip_input):] + self._unet_skip_input\n",
    "        #x = x.transpose(1, 2)   # # (batch, d_model , lag) to (batch, lag, d_model)\n",
    "        else:\n",
    "            pass\n",
    "        if self.verbose : \n",
    "            print(\"reshape - > x.shape\", x.shape)\n",
    "        x = x.reshape(-1, self.input_len, self.input_dim)\n",
    "        \n",
    "        if isinstance(self.kernel, nn.Linear):\n",
    "            x = x.reshape(-1, self.input_len * self.input_dim)\n",
    "\n",
    "        if self.verbose : \n",
    "            print(\"after reshape - > x.shape\", x.shape)\n",
    "        x = self.f(x)\n",
    "\n",
    "        if self.verbose : \n",
    "            print(\"after x = self.f(x) - > x.shape\", x.shape)\n",
    "\n",
    "        if isinstance(self.kernel, nn.Linear):\n",
    "            x = x.reshape(-1, self.output_len, self.output_dim)\n",
    "        assert x.shape[1] == self.output_len and x.shape[2] == self.output_dim\n",
    "\n",
    "        if not self.transpose:\n",
    "          self._unet_skip_output = x\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear MLP Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(Kernel):\n",
    "    def __init__(self, input_dim, input_len, \n",
    "                 output_dim, output_len, params={}):\n",
    "        super(Linear, self).__init__(input_dim, input_len, \n",
    "                 output_dim, output_len)\n",
    "        # declear parameters\n",
    "        self.activation = \"tanh\"\n",
    "        self.drop_out_p = 0.05\n",
    "        self.kernel_hidden_layer = 0\n",
    "        self.update_params(params=params)\n",
    "\n",
    "        # compute input and output size\n",
    "        self.in_size = input_len*input_dim\n",
    "        self.out_size = output_len*output_dim\n",
    "\n",
    "        # prepare layers\n",
    "        self.layers = []\n",
    "\n",
    "        # check in encoder or decoder \n",
    "        self.is_in_encoder = (self.input_len >= self.output_len)\n",
    "        self.is_in_decoder = not self.is_in_encoder\n",
    "\n",
    "        # in encoder\n",
    "        if self.is_in_encoder:\n",
    "          gap = int((self.in_size - self.out_size) / (self.kernel_hidden_layer + 1))\n",
    "          self.hidden_size_list = [self.in_size - i * gap for i in range(1, self.kernel_hidden_layer + 1)]\n",
    "        \n",
    "        # in decoder\n",
    "        else:\n",
    "          gap = int((self.out_size - self.in_size) / (self.kernel_hidden_layer + 1))\n",
    "          self.hidden_size_list = [self.in_size + i * gap for i in range(1, self.kernel_hidden_layer + 1)]\n",
    "        # add linear layers\n",
    "        for i in range(self.kernel_hidden_layer):\n",
    "            self.layers.append(nn.Linear(self.in_size, self.hidden_size_list[i]))\n",
    "\n",
    "            if self.activation.lower() == \"relu\":\n",
    "                self.layers.append(nn.ReLU())\n",
    "            elif self.activation.lower() == \"tanh\": \n",
    "                self.layers.append(nn.Tanh())\n",
    "\n",
    "            self.layers.append(nn.Dropout(self.drop_out_p))\n",
    "            self.in_size = self.hidden_size_list[i]\n",
    "\n",
    "        self.layers.append(nn.Linear(self.in_size, self.out_size))\n",
    "\n",
    "        self.layers = nn.Sequential(* self.layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, self.input_len * self.input_dim)\n",
    "        #print(\"x.shape,\", x.shape)\n",
    "        x = self.layers(x)\n",
    "        x = x.reshape(-1, self.output_len, self.output_dim)\n",
    "        #print(\"x.shape,\", x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "KernelWrapper(\n",
      "  (kernel): Linear(\n",
      "    (layers): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=320, bias=True)\n",
      "      (1): Tanh()\n",
      "      (2): Dropout(p=0.05, inplace=False)\n",
      "      (3): Linear(in_features=320, out_features=512, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kw = KernelWrapper(Linear, input_dim=128, input_len=1, \n",
    "                 output_dim=128, output_len=4, \n",
    "                 kernel_hidden_layer=1, \n",
    "                 params={\"unet_skip_mode\":\"concat\", \n",
    "                            \"kernel_hidden_layer\":2, \n",
    "                            \"drop_out_p\":0.05, \n",
    "                            \"activation\":\"tanh\"}, \n",
    "                            verbose=False)\n",
    "print(kw)\n",
    "print(kw.kernel.is_in_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "x = kw(torch.rand((4,1,128)))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class 'torch.nn.modules.linear.Linear'> is a nn.Linear Kernel\n",
      "KernelWrapper(\n",
      "  (kernel): Linear(in_features=512, out_features=128, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "kw = KernelWrapper(nn.Linear, input_dim=128, input_len=4, \n",
    "                 output_dim=128, output_len=1, \n",
    "                 kernel_hidden_layer=1, \n",
    "                 params={\"unet_skip_mode\":\"concat\", \n",
    "                            \"kernel_hidden_layer\":2, \n",
    "                            \"drop_out_p\":0.05, \n",
    "                            \"activation\":\"tanh\"}, \n",
    "                            verbose=False)\n",
    "print(kw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "x = kw(torch.rand((4,4,128)))\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(Kernel):\n",
    "    def __init__(self, input_dim, input_len, \n",
    "                 output_dim, output_len, params={}):\n",
    "        super(LSTM, self).__init__(input_dim, input_len, \n",
    "                 output_dim, output_len)\n",
    "        # declear parameters\n",
    "        self.drop_out_p = 0.05\n",
    "        self.kernel_hidden_layer = 0\n",
    "        self.update_params(params=params)\n",
    "\n",
    "        self.lstm_dim = max(input_dim, output_dim)\n",
    "        self.lstm_len = max(input_len, output_len)\n",
    "\n",
    "        # compute input and output size\n",
    "        self.in_size = input_len*input_dim\n",
    "        self.out_size = output_len*output_dim\n",
    "        self.lstm_size = self.lstm_dim*self.lstm_len\n",
    "\n",
    "        # prepare layers\n",
    "        self.layers = []\n",
    "\n",
    "        # check in encoder or decoder \n",
    "        self.is_in_encoder = (self.input_len >= self.output_len)\n",
    "        self.is_in_decoder = not self.is_in_encoder\n",
    "\n",
    "        # Define the LSTM and Linear layers\n",
    "        self.linear_projection_in = nn.Linear(self.in_size, self.lstm_size)\n",
    "        self.linear_projection_out = nn.Linear(self.lstm_size, self.out_size)\n",
    "\n",
    "        self.lstm = nn.LSTM(self.lstm_dim, self.lstm_dim, \n",
    "                            self.kernel_hidden_layer, dropout=self.drop_out_p, \n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for LSTM. If we are in encoder mode, process the input sequence through LSTM\n",
    "        and use the last hidden state to compute the final output using the linear layer.\n",
    "        \"\"\"\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.in_size)\n",
    "        #print(x.shape)\n",
    "        x = self.linear_projection_in(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.lstm_len, self.lstm_dim)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        x, (h_n, c_n) = self.lstm(x)  # x, lstm_out contains all hidden states, h_n is the last hidden state\n",
    "\n",
    "        # Use the last hidden state (h_n) for linear transformation\n",
    "        #print(x.shape, h_n.shape, c_n.shape)\n",
    "        # Apply linear transformation\n",
    "        x = x.reshape(-1, self.lstm_size)\n",
    "        x = self.linear_projection_out(x)\n",
    "        x = x.reshape(-1, self.output_len, self.output_dim)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.LSTM'> is a Kernel\n",
      "KernelWrapper(\n",
      "  (kernel): LSTM(\n",
      "    (linear_projection_in): Linear(in_features=4, out_features=512, bias=True)\n",
      "    (linear_projection_out): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (lstm): LSTM(128, 128, batch_first=True, dropout=0.05)\n",
      "  )\n",
      ")\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyou\\AppData\\Local\\Continuum\\anaconda3\\envs\\Base\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.05 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n"
     ]
    }
   ],
   "source": [
    "kw = KernelWrapper(LSTM, input_dim=1, input_len=4, \n",
    "                 output_dim=128, output_len=1, \n",
    "                 kernel_hidden_layer=1, \n",
    "                 params={\"unet_skip_mode\":\"add\", \n",
    "                            \"kernel_hidden_layer\":1, \n",
    "                            \"drop_out_p\":0.05,\n",
    "                            \"activation\":\"tanh\"}, \n",
    "                            verbose=False)\n",
    "print(kw)\n",
    "print(kw.kernel.is_in_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 4, 1])\n",
      "torch.Size([13, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(13,4,1))\n",
    "print(x.shape)\n",
    "x = kw(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(Kernel):\n",
    "    def __init__(self, input_dim, input_len, \n",
    "                 output_dim, output_len, params={}):\n",
    "        super(RNN, self).__init__(input_dim, input_len, \n",
    "                 output_dim, output_len)\n",
    "        # declear parameters\n",
    "        self.drop_out_p = 0.05\n",
    "        self.kernel_hidden_layer = 0\n",
    "        self.update_params(params=params)\n",
    "\n",
    "\n",
    "        self.lstm_dim = max(input_dim, output_dim)\n",
    "        self.lstm_len = max(input_len, output_len)\n",
    "\n",
    "        # compute input and output size\n",
    "        self.in_size = input_len*input_dim\n",
    "        self.out_size = output_len*output_dim\n",
    "        self.lstm_size = self.lstm_dim*self.lstm_len\n",
    "\n",
    "        # prepare layers\n",
    "        self.layers = []\n",
    "\n",
    "        # check in encoder or decoder \n",
    "        self.is_in_encoder = (self.input_len >= self.output_len)\n",
    "        self.is_in_decoder = not self.is_in_encoder\n",
    "\n",
    "        # Define the LSTM and Linear layers\n",
    "        self.linear_projection_in = nn.Linear(self.in_size, self.lstm_size)\n",
    "        self.linear_projection_out = nn.Linear(self.lstm_size, self.out_size)\n",
    "\n",
    "        self.lstm = nn.RNN(self.lstm_dim, self.lstm_dim, \n",
    "                            self.kernel_hidden_layer, dropout=self.drop_out_p, \n",
    "                            batch_first=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for LSTM. If we are in encoder mode, process the input sequence through LSTM\n",
    "        and use the last hidden state to compute the final output using the linear layer.\n",
    "        \"\"\"\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.in_size)\n",
    "        #print(x.shape)\n",
    "        x = self.linear_projection_in(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.lstm_len, self.lstm_dim)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        x, _ = self.lstm(x)  # x, lstm_out contains all hidden states, h_n is the last hidden state\n",
    "\n",
    "        # Use the last hidden state (h_n) for linear transformation\n",
    "        #print(x.shape, h_n.shape, c_n.shape)\n",
    "        # Apply linear transformation\n",
    "        x = x.reshape(-1, self.lstm_size)\n",
    "        x = self.linear_projection_out(x)\n",
    "        x = x.reshape(-1, self.output_len, self.output_dim)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.RNN'> is a Kernel\n",
      "KernelWrapper(\n",
      "  (kernel): RNN(\n",
      "    (linear_projection_in): Linear(in_features=4, out_features=512, bias=True)\n",
      "    (linear_projection_out): Linear(in_features=512, out_features=128, bias=True)\n",
      "    (lstm): RNN(128, 128, batch_first=True, dropout=0.05)\n",
      "  )\n",
      ")\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "kw = KernelWrapper(RNN, input_dim=1, input_len=4, \n",
    "                 output_dim=128, output_len=1, \n",
    "                 kernel_hidden_layer=1, \n",
    "                 params={\"unet_skip_mode\":\"add\", \n",
    "                            \"kernel_hidden_layer\":1, \n",
    "                            \"drop_out_p\":0.05,\n",
    "                            \"activation\":\"tanh\"}, \n",
    "                            verbose=False)\n",
    "print(kw)\n",
    "print(kw.kernel.is_in_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 4, 1])\n",
      "torch.Size([13, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(13,4,1))\n",
    "print(x.shape)\n",
    "x = kw(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = num_heads\n",
    "        self.d_model = d_model\n",
    "        assert d_model % self.num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        self.depth = d_model // self.num_heads\n",
    "        \n",
    "        # Linear layers for queries, keys, and values\n",
    "        self.Wq = nn.Linear(d_model, d_model)\n",
    "        self.Wk = nn.Linear(d_model, d_model)\n",
    "        self.Wv = nn.Linear(d_model, d_model)\n",
    "        \n",
    "        # Output linear layer\n",
    "        self.fc = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size = x.size(0)\n",
    "\n",
    "        # Linear projections for Q, K, V\n",
    "        Q = self.Wq(x).view(batch_size, -1, self.num_heads, self.depth)\n",
    "        K = self.Wk(x).view(batch_size, -1, self.num_heads, self.depth)\n",
    "        V = self.Wv(x).view(batch_size, -1, self.num_heads, self.depth)\n",
    "\n",
    "        # Permute to bring num_heads dimension to second position\n",
    "        Q = Q.permute(0, 2, 1, 3)\n",
    "        K = K.permute(0, 2, 1, 3)\n",
    "        V = V.permute(0, 2, 1, 3)\n",
    "\n",
    "        # Scaled dot-product attention\n",
    "        scores = torch.matmul(Q, K.permute(0, 1, 3, 2)) / math.sqrt(self.depth)\n",
    "        \n",
    "        if mask is not None:\n",
    "            mask = mask.unsqueeze(1).unsqueeze(2)  # (batch_size, 1, 1, seq_len)\n",
    "            scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "        \n",
    "        attention = F.softmax(scores, dim=-1)\n",
    "\n",
    "        # Weighted sum of value vectors\n",
    "        out = torch.matmul(attention, V)\n",
    "        out = out.permute(0, 2, 1, 3).contiguous().view(batch_size, -1, self.d_model)\n",
    "\n",
    "        # Final linear transformation\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=500):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        if d_model % 2 == 1:\n",
    "            d_model_1 = d_model + 1\n",
    "        else:\n",
    "            d_model_1 = d_model\n",
    "\n",
    "        pe = torch.zeros(max_len, d_model_1)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model_1, 2).float() * (-math.log(10000.0) / d_model_1))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe_const', pe[:, :d_model])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.pe_const[:x.size(1), :].unsqueeze(0)\n",
    "        return x\n",
    "\n",
    "class AttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(AttentionBlock, self).__init__()\n",
    "        self.multi_head_attention = MultiHeadAttention(d_model, num_heads)\n",
    "        self.relu = nn.LeakyReLU()\n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "\n",
    "    def forward(self, x, mask=None):\n",
    "        # First residual connection\n",
    "        residual = x\n",
    "        x = self.multi_head_attention(x, mask)\n",
    "        x = self.relu(x) + residual\n",
    "\n",
    "        # Second residual connection\n",
    "        residual = x\n",
    "        x = self.linear(x)\n",
    "        x = x + residual\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(Kernel):\n",
    "    def __init__(self, input_dim, input_len, \n",
    "                 output_dim, output_len, params={}):\n",
    "        super(Transformer, self).__init__(input_dim, input_len, \n",
    "                 output_dim, output_len)\n",
    "        # declear parameters\n",
    "        self.drop_out_p = 0.05\n",
    "        self.kernel_hidden_layer = 0\n",
    "        self.num_heads = 2\n",
    "        self.update_params(params=params)\n",
    "\n",
    "\n",
    "        self.lstm_dim = max(input_dim, output_dim)\n",
    "        self.lstm_len = max(input_len, output_len)\n",
    "\n",
    "        # compute input and output size\n",
    "        self.in_size = input_len*input_dim\n",
    "        self.out_size = output_len*output_dim\n",
    "        self.lstm_size = self.lstm_dim*self.lstm_len\n",
    "\n",
    "        # prepare layers\n",
    "        self.layers = []\n",
    "\n",
    "        # check in encoder or decoder \n",
    "        self.is_in_encoder = (self.input_len >= self.output_len)\n",
    "        self.is_in_decoder = not self.is_in_encoder\n",
    "\n",
    "        # Define the LSTM and Linear layers\n",
    "        self.linear_projection_in = nn.Linear(self.in_size, self.lstm_size)\n",
    "        self.linear_projection_out = nn.Linear(self.lstm_size, self.out_size)\n",
    "\n",
    "        self.attention = nn.Sequential(*[\n",
    "                                AttentionBlock(d_model=self.lstm_dim, \n",
    "                                num_heads=self.num_heads) for i in range(self.kernel_hidden_layer)])\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for LSTM. If we are in encoder mode, process the input sequence through LSTM\n",
    "        and use the last hidden state to compute the final output using the linear layer.\n",
    "        \"\"\"\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.in_size)\n",
    "        #print(x.shape)\n",
    "        x = self.linear_projection_in(x)\n",
    "        #print(x.shape)\n",
    "        x = x.reshape(-1, self.lstm_len, self.lstm_dim)\n",
    "        #print(x.shape)\n",
    "\n",
    "        # Pass through LSTM\n",
    "        x = self.attention(x)  # x, lstm_out contains all hidden states, h_n is the last hidden state\n",
    "\n",
    "        # Use the last hidden state (h_n) for linear transformation\n",
    "        #print(x.shape, h_n.shape, c_n.shape)\n",
    "        # Apply linear transformation\n",
    "        x = x.reshape(-1, self.lstm_size)\n",
    "        x = self.linear_projection_out(x)\n",
    "        x = x.reshape(-1, self.output_len, self.output_dim)\n",
    "        #print(x.shape)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.Transformer'> is a Kernel\n",
      "KernelWrapper(\n",
      "  (kernel): Transformer(\n",
      "    (linear_projection_in): Linear(in_features=128, out_features=512, bias=True)\n",
      "    (linear_projection_out): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (attention): Sequential(\n",
      "      (0): AttentionBlock(\n",
      "        (multi_head_attention): MultiHeadAttention(\n",
      "          (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "          (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "        )\n",
      "        (relu): LeakyReLU(negative_slope=0.01)\n",
      "        (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "kw = KernelWrapper(Transformer, input_dim=128, input_len=1, \n",
    "                 output_dim=128, output_len=4, \n",
    "                 kernel_hidden_layer=1, \n",
    "                 params={\"unet_skip_mode\":\"add\",\n",
    "                            \"kernel_hidden_layer\":1, \n",
    "                            \"drop_out_p\":0.05,\n",
    "                            \"activation\":\"tanh\"}, \n",
    "                            verbose=False)\n",
    "print(kw)\n",
    "print(kw.kernel.is_in_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([13, 1, 128])\n",
      "torch.Size([13, 4, 128])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(size=(13,1,128))\n",
    "print(x.shape)\n",
    "x = kw(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_params(self, params):\n",
    "    # Iterate over all fields in the class and update if they exist in params\n",
    "    self.params = params \n",
    "    for key, value in params.items():\n",
    "        setattr(self, key, value)  # Set the attribute from params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KUNetEncoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, input_len=4, \n",
    "                 n_width=[1], n_height=[4, 4], \n",
    "                 output_dim=128, output_len=1, \n",
    "                 hidden_dim=[128]*3, \n",
    "                 kernel=[nn.Linear]*3, kernel_hidden_layer=[1]*3, \n",
    "                 verbose=False, params={}):\n",
    "        super(KUNetEncoder, self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.input_len = input_len\n",
    "        self.n_width = n_width\n",
    "        self.n_height = n_height\n",
    "        self.output_dim = output_dim\n",
    "        self.output_len = output_len\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel = kernel\n",
    "        self.kernel_hidden_layer = kernel_hidden_layer\n",
    "\n",
    "        self.verbose = verbose\n",
    "\n",
    "        update_params(self, params)\n",
    "\n",
    "        assert isinstance(n_width, list)\n",
    "        assert isinstance(n_height, list)\n",
    "        assert isinstance(kernel, list)\n",
    "        assert isinstance(hidden_dim, list)\n",
    "        assert isinstance(kernel_hidden_layer, list)\n",
    "\n",
    "        # Create lag_list for  Optic Nerve transformer model\n",
    "        # lag_list = [lag, n_height_1, ...,n_height_n, n_width_1, n_width_n]\n",
    "        self.lag_list = [input_len]\n",
    "        if not(len(self.n_height) == 1 and self.n_height[0] ==1):\n",
    "            self.lag_list =  self.lag_list + list(reversed(self.n_height))\n",
    "        if not(len(self.n_width) == 1 and  self.n_width[0] ==1):\n",
    "            self.lag_list =  self.lag_list + list(reversed(self.n_width))\n",
    "        if self.verbose:\n",
    "            print(\"self.lag_list\", self.lag_list)\n",
    "            print(\"hidden_dim\", hidden_dim)\n",
    "\n",
    "        # declear model\n",
    "        kernel_list = kernel\n",
    "        kernel_hidden_layer_list = kernel_hidden_layer\n",
    "        hidden_dim_list = hidden_dim\n",
    "        kernel_hidden_layer = kernel_hidden_layer_list[0]\n",
    "        kernel = kernel_list[0]\n",
    "        hidden_dim = hidden_dim_list[0]\n",
    "\n",
    "        self.layers = [KernelWrapper(kernel, \n",
    "                                    input_dim=input_dim, input_len=self.lag_list[0], \n",
    "                                    output_dim=hidden_dim, output_len=1, \n",
    "                                    kernel_hidden_layer=kernel_hidden_layer, verbose=verbose, params=params)]\n",
    "        self.layers = self.layers + [KernelWrapper(kernel_list[i+1], \n",
    "                                                    input_dim=hidden_dim_list[i], input_len=l, \n",
    "                                                    output_dim=hidden_dim_list[i+1], output_len=1, \n",
    "                                                    kernel_hidden_layer=kernel_hidden_layer_list[i+1], verbose=verbose, params=params) for i, l in enumerate(self.lag_list[1:-1])]\n",
    "\n",
    "        kernel = kernel_list[len(self.layers)]\n",
    "        kernel_hidden_layer = kernel_hidden_layer_list[len(self.layers)]\n",
    "        hidden_dim = hidden_dim_list[len(self.layers)-1]\n",
    "        self.layers.append(KernelWrapper(kernel, \n",
    "                            input_dim=hidden_dim, input_len=self.lag_list[-1], \n",
    "                            output_dim=output_dim, output_len=output_len, \n",
    "                            kernel_hidden_layer=kernel_hidden_layer, verbose=verbose, params=params))\n",
    "         \n",
    "        self.layers = nn.Sequential(* self.layers)\n",
    "\n",
    "        for i, f in enumerate(self.layers):\n",
    "          if i+1 < len(self.lag_list):\n",
    "           f.next_layer_lag = self.lag_list[i+1]\n",
    "           f.next_d_model = self.hidden_dim[i]\n",
    "          else:\n",
    "           f.next_d_model = self.output_dim\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        # reshape\n",
    "        shape : (batch, [height]*lag, [width]*d_model)\n",
    "        shape : (batch, [height], lag, [width], d_model)\n",
    "        shape : (batch, [width], [height], lag, d_model)\n",
    "\n",
    "        # layer 1 : process height\n",
    "        1st step:  x -> model(x)\n",
    "                (batch * [width] * [height] , lag, d_model) -> (batch * [width] * [height], 1, d_model)\n",
    "                output shape : (batch * [width], lag=height, d_model)\n",
    "\n",
    "        # layer 2 : process width\n",
    "        2st step:  x -> model(x)\n",
    "                (batch * [width], lag=1, d_model)) -> (batch, lag=width, d_model)\n",
    "                output shape : (batch, lag=1, d_model))\n",
    "\n",
    "        # layer 3 : process output\n",
    "        3st step:  x -> model(x)\n",
    "              (batch, lag=1, d_model)) -> (batch, out_size)\n",
    "        \"\"\"\n",
    "        x_shape = x.shape # (batch, height*lag, width*d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x) Input x.shape: \", x.shape)\n",
    "\n",
    "        # layer 1 : process height\n",
    "        x = x.reshape((-1,)+ (np.prod(self.n_height),) +(self.input_len,) + (np.prod(self.n_width),) + (1,) + (self.input_dim,))\n",
    "        # (batch, [height], lag, [width], d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x) x = x.reshape((-1,) + tuple(self.n_width) + (self.input_dim,) + tuple(self.n_height) + (1,) +(self.input_len,)).shape \", x.shape)\n",
    "\n",
    "        x = x.transpose(2, 4)\n",
    "        x = x.reshape((-1,) + (np.prod(self.n_height),) + (np.prod(self.n_width),) + (self.input_len,) + (self.input_dim,) )\n",
    "        # (batch, [height], [width], lag, d_model)\n",
    "        x = x.transpose(1,2)\n",
    "        # (batch, [width], [height], lag, d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x)  x = x.transpose(1+len(self.n_width), 1+len(self.n_width)+len(self.n_height)+1).shape \", x.shape)\n",
    "\n",
    "        x = x.reshape((-1, self.input_len, self.input_dim))\n",
    "        # (batch * width * height, lag, d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x) x = x.reshape((-1, self.input_len, self.input_dim)).shape \", x.shape)\n",
    "\n",
    "\n",
    "        x = self.layers(x)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x) self.layers(x).shape \", x.shape)\n",
    "\n",
    "        x = x.reshape((-1, self.output_len, self.output_dim))  # (batch * width * height , lag, d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Encoder.forward(x) x = x.reshape((-1, self.output_len, self.output_dim)).shape \", x.shape)\n",
    "\n",
    "        # x = F.sigmoid(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "KUNetEncoder(\n",
      "  (layers): Sequential(\n",
      "    (0): KernelWrapper(\n",
      "      (kernel): Linear(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=320, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Dropout(p=0.05, inplace=False)\n",
      "          (3): Linear(in_features=320, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): KernelWrapper(\n",
      "      (kernel): Linear(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=320, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Dropout(p=0.05, inplace=False)\n",
      "          (3): Linear(in_features=320, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): KernelWrapper(\n",
      "      (kernel): Linear(\n",
      "        (layers): Sequential(\n",
      "          (0): Linear(in_features=512, out_features=320, bias=True)\n",
      "          (1): Tanh()\n",
      "          (2): Dropout(p=0.05, inplace=False)\n",
      "          (3): Linear(in_features=320, out_features=128, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([13, 64, 128])\n",
      "torch.Size([13, 1, 128])\n"
     ]
    }
   ],
   "source": [
    "kun_encoder = KUNetEncoder(input_dim=128, input_len=4, \n",
    "                 n_width=[1], n_height=[4, 4], \n",
    "                 output_dim=128, output_len=1, \n",
    "                 hidden_dim=[128,128,128], kernel_hidden_layer=[1,1,1], \n",
    "                 kernel=[Linear]*3, verbose=False, params={})\n",
    "print(kun_encoder)\n",
    "x = torch.rand(size=(13,64,128))\n",
    "print(x.shape)\n",
    "x = kun_encoder(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KUNetDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, input_len=4, \n",
    "                 n_width=[1], n_height=[4, 4], \n",
    "                 output_dim=128, output_len=1, \n",
    "                 hidden_dim=[128]*3,  kernel_hidden_layer=[1]*3, \n",
    "                 kernel=[nn.Linear]*3, verbose=False,\n",
    "                 params={}):\n",
    "        super(KUNetDecoder, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.kernel_hidden_layer = kernel_hidden_layer\n",
    "        self.n_width = n_width\n",
    "        self.n_height = n_height\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.input_len = input_len\n",
    "        self.output_len = output_len\n",
    "\n",
    "        self.unet_skip_concat = True\n",
    "        self.unet_skip = True\n",
    "\n",
    "        self.verbose=verbose\n",
    "\n",
    "        self.total_width = np.prod(self.n_width) * output_dim\n",
    "        self.total_height = np.prod(self.n_height) * output_len\n",
    " \n",
    "        update_params(self, params)\n",
    "\n",
    "        assert isinstance(n_width, list)\n",
    "        assert isinstance(n_height, list)\n",
    "        assert isinstance(kernel, list)\n",
    "        assert isinstance(hidden_dim, list)\n",
    "        assert isinstance(kernel_hidden_layer, list)\n",
    "\n",
    "        # Create model Optic Nerve transformer\n",
    "        # lag_list = [lag, n_height_1, ...,n_height_n, n_width_1, n_width_n]\n",
    "        #self.attention_layers_0 = MultiLayerModel(d_model, num_heads, num_layers, lag=lag, out_size=d_model)\n",
    "        #self.attention_layers_1 = MultiLayerModel(d_model, num_heads, num_layers, lag=n_height, out_size=d_model)\n",
    "        #self.attention_layers_2 = MultiLayerModel(d_model, num_heads, num_layers, lag=n_width, out_size=out_size)\n",
    "\n",
    "        self.lag_list = [input_len] # [1]\n",
    "        if not(len(self.n_width) == 1 and  self.n_width[0] ==1):\n",
    "            self.lag_list =  self.lag_list + list(self.n_width)\n",
    "        if not(len(self.n_height) == 1 and self.n_height[0] ==1):\n",
    "            self.lag_list =  self.lag_list + list(self.n_height) #[10, 10]\n",
    "\n",
    "        # declear model\n",
    "        kernel_list = list(reversed(kernel))\n",
    "        kernel_hidden_layer_list = list(reversed(kernel_hidden_layer))\n",
    "        hidden_dim_list = list(reversed(hidden_dim))\n",
    "        kernel_hidden_layer = kernel_hidden_layer_list[0]\n",
    "        kernel = kernel_list[0]\n",
    "        hidden_dim = hidden_dim_list[0]\n",
    "        self.layers = [KernelWrapper(kernel, \n",
    "                        input_dim=input_dim, input_len=1, \n",
    "                        output_dim=hidden_dim, output_len=self.lag_list[1], \n",
    "                        kernel_hidden_layer =kernel_hidden_layer, verbose=verbose, params=params)]\n",
    "\n",
    "        multiple = 2 if self.unet_skip_concat else 1\n",
    "        #print(\"self.concat\", self.concat)\n",
    "        self.layers = self.layers + [KernelWrapper(kernel_list[i+1], \n",
    "                                        input_dim=hidden_dim_list[i]*multiple, input_len=1, \n",
    "                                        output_dim=hidden_dim_list[i+1], output_len=l, \n",
    "                                        kernel_hidden_layer=kernel_hidden_layer_list[i+1], verbose=verbose, params=params) for i, l in enumerate(self.lag_list[2:])]\n",
    "\n",
    "        kernel = kernel_list[-1]\n",
    "        kernel_hidden_layer = kernel_hidden_layer_list[-1]\n",
    "        hidden_dim = hidden_dim_list[-1]\n",
    "        self.layers.append(KernelWrapper(kernel, \n",
    "                            input_dim=hidden_dim*multiple, input_len=1, \n",
    "                            output_dim=output_dim, output_len=output_len, \n",
    "                            kernel_hidden_layer=kernel_hidden_layer, verbose=verbose, params=params)) # output_len = 10\n",
    "        \n",
    "        self.layers = nn.Sequential(*self.layers)\n",
    "\n",
    "        for i, f in enumerate(self.layers):\n",
    "          if i+1 < len(self.lag_list):\n",
    "           f.next_layer_lag = self.lag_list[i+1]\n",
    "           f.next_d_model = self.hidden_dim[i]\n",
    "          else:\n",
    "           f.next_d_model = self.output_dim\n",
    "\n",
    "          f.transpose = True\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        \"\"\"\n",
    "        # reshape\n",
    "        1, shape : (batch, 1, d_model)\n",
    "        2, shape : (batch*[width], 1, d_model)\n",
    "        3, shape : (batch*[width]*[height], lag d_model)\n",
    "        4, shape : (batch, [width], [height], lag, d_model)\n",
    "        5, shape : (batch, [height]*lag, [width]*d_model)\n",
    "\n",
    "        # layer 3 : process output\n",
    "        3st step:  x -> model(x)\n",
    "              (batch, lag=1, d_model)) -> (batch, out_size)\n",
    "\n",
    "        # layer 2 : process width\n",
    "        2st step:  x -> model(x)\n",
    "                (batch, lag=1, d_model)) -> (batch, lag=width, d_model)\n",
    "                output shape : (batch * width, lag=1, d_model))\n",
    "\n",
    "        # layer 1 : process height\n",
    "        1st step:  x -> model(x)\n",
    "                (batch * [width] , lag=1, d_model) -> (batch * [width],  lag=[height], d_model)\n",
    "                output shape : (batch * [width] * [height], lag=1, d_model)\n",
    "\n",
    "        \"\"\"\n",
    "        x_shape = x.shape # (batch, 1, d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Decoder.forward(x) start x.shape \", x.shape)\n",
    "\n",
    "        x = self.layers(x)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Decoder.forward(x) self.layers(x).shape \", x.shape)  # (batch, lag, d_model)\n",
    "\n",
    "        #x = x.transpose(1, 2) # (batch, d_model, lag)\n",
    "        #print(\"x = x.transpose(1, 2).shape \", x.shape)\n",
    "\n",
    "        #x = x.reshape((-1, self.output_len, self.output_dim))  # (batch * width * height , lag, d_model)\n",
    "        #print(\"x.shape \", x.shape)\n",
    "\n",
    "        # layer 1 : process height\n",
    "        x = x.reshape((-1,) + (np.prod(self.n_width),) + (1, ) + (np.prod(self.n_height),) + (self.output_len,) + (self.output_dim,) ) # (batch, [width], d_model, [height], lag)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Decoder.forward(x) x.reshape((-1,)+ tuple(self.n_width) + (1,) + tuple(self.n_height) + (self.output_dim,)  + (self.output_len,)).reshape \", x.shape)\n",
    "\n",
    "        x = x.transpose(1, 3)\n",
    "        # (batch, [width], [height], lag, d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Decoder.forward(x) x.transpose(2+len(self.n_width), 2+len(self.n_width)+2+len(self.n_height)).shape \", x.shape)\n",
    "\n",
    "        x = x.transpose(2, 4)\n",
    "        # (batch, [height]*lag, [width]*d_model)\n",
    "\n",
    "        x = x.reshape((x_shape[0], self.total_height, self.total_width))\n",
    "        # (batch, height * lag,   width * d_model)\n",
    "        if self.verbose:\n",
    "          print(\"-KUN-Decoder.forward(x) x.reshape((x_shape[0], self.total_width, self.total_height*self.input_len)).shape \", x.shape)\n",
    "\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "Sequential(\n",
      "  (0): KernelWrapper(\n",
      "    (kernel): Linear(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=320, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Dropout(p=0.05, inplace=False)\n",
      "        (3): Linear(in_features=320, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (1): KernelWrapper(\n",
      "    (kernel): Linear(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=320, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Dropout(p=0.05, inplace=False)\n",
      "        (3): Linear(in_features=320, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (2): KernelWrapper(\n",
      "    (kernel): Linear(\n",
      "      (layers): Sequential(\n",
      "        (0): Linear(in_features=128, out_features=320, bias=True)\n",
      "        (1): Tanh()\n",
      "        (2): Dropout(p=0.05, inplace=False)\n",
      "        (3): Linear(in_features=320, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([13, 1, 128])\n",
      "-KUN-Decoder.forward(x) start x.shape  torch.Size([13, 1, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([13, 1, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([13, 1, 128])\n",
      "after reshape - > x.shape torch.Size([13, 1, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([13, 1, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([13, 4, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([13, 4, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([13, 4, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([13, 4, 128])\n",
      "after reshape - > x.shape torch.Size([52, 1, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([52, 1, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([52, 4, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([52, 4, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([52, 4, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([52, 4, 128])\n",
      "after reshape - > x.shape torch.Size([208, 1, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([208, 1, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([208, 4, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([208, 4, 128])\n",
      "-KUN-Decoder.forward(x) self.layers(x).shape  torch.Size([208, 4, 128])\n",
      "-KUN-Decoder.forward(x) x.reshape((-1,)+ tuple(self.n_width) + (1,) + tuple(self.n_height) + (self.output_dim,)  + (self.output_len,)).reshape  torch.Size([13, 1, 1, 16, 4, 128])\n",
      "-KUN-Decoder.forward(x) x.transpose(2+len(self.n_width), 2+len(self.n_width)+2+len(self.n_height)).shape  torch.Size([13, 16, 1, 1, 4, 128])\n",
      "-KUN-Decoder.forward(x) x.reshape((x_shape[0], self.total_width, self.total_height*self.input_len)).shape  torch.Size([13, 64, 128])\n",
      "torch.Size([13, 64, 128])\n"
     ]
    }
   ],
   "source": [
    "kun_decoder = KUNetDecoder(input_dim=128, input_len=1, \n",
    "                 n_width=[1], n_height=[4, 4], \n",
    "                 output_dim=128, output_len=4, \n",
    "                 hidden_dim=[128,128,128], kernel_hidden_layer=[1,1,1], \n",
    "                 kernel=[Linear]*3, verbose=True, params={\"unet_skip\":True, \n",
    "                 \"unet_skip_concat\":False,\n",
    "                 })\n",
    "print(kun_decoder.layers)\n",
    "x = torch.rand(size=(13,1,128))\n",
    "print(x.shape)\n",
    "x = kun_decoder(x)\n",
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KUNetEncoderDecoder(nn.Module):\n",
    "    def __init__(self, input_dim=128, input_len=4, \n",
    "                 n_width=[1], n_height=[4, 4], \n",
    "                 latent_dim=128, latent_len=1, \n",
    "                 output_dim=128, output_len=4, \n",
    "                 hidden_dim=[128]*3, \n",
    "                 kernel=[nn.Linear]*3, kernel_hidden_layer=[1, 1, 1], \n",
    "                 verbose=False, params={}):\n",
    "        super(KUNetEncoderDecoder, self).__init__()\n",
    "\n",
    "        self.unet_skip = True \n",
    "\n",
    "        update_params(self, params)\n",
    "\n",
    "        self.encoder = KUNetEncoder(input_dim=input_dim, input_len=input_len, \n",
    "                            n_width=n_width, n_height=n_height, \n",
    "                            output_dim=latent_dim, output_len=latent_len, \n",
    "                            hidden_dim=hidden_dim, kernel_hidden_layer=kernel_hidden_layer, \n",
    "                            kernel=kernel, verbose=verbose, params=params)\n",
    "        \n",
    "        self.decoder = KUNetDecoder(input_dim=latent_dim, input_len=latent_len, \n",
    "                            n_width=n_width, n_height=n_height, \n",
    "                            output_dim=output_dim, output_len=output_len, \n",
    "                            hidden_dim=hidden_dim, kernel_hidden_layer=kernel_hidden_layer, \n",
    "                            kernel=kernel, verbose=verbose, params=params)\n",
    "        \n",
    "        self.latent_condition = None #torch.zeros((1,1,128))\n",
    "\n",
    "    def forward(self, x):\n",
    "        #seq_last = x[:,-1:,:]\n",
    "        #print(\"seq_last.shape \", seq_last.shape)\n",
    "        #x = x - seq_last\n",
    "\n",
    "        x_shape = x.shape # (batch, lag, d_model)\n",
    "        #print(\"start x.shape \", x.shape)\n",
    "\n",
    "        #x = x.transpose(1, 2) # (batch, d_model, lag)\n",
    "        #print(\" x.transpose(1, 2).shape \", x.shape)\n",
    "\n",
    "        encoder = self.encoder\n",
    "        decoder = self.decoder\n",
    "        z = encoder(x)\n",
    "        if self.latent_condition is not None:\n",
    "          z[:, :, 128:256] = self.latent_condition\n",
    "\n",
    "        if self.unet_skip:\n",
    "          #print(\"self.encoder(x).shape \", z.shape)\n",
    "          _unet_skip_output_list = []\n",
    "          for f in encoder.layers:\n",
    "            #print(f.transpose)\n",
    "            #print(\"f._unet_skip_output.shape\", f._unet_skip_output.shape)\n",
    "            _unet_skip_output_list.append(f._unet_skip_output)\n",
    "\n",
    "          for i, f in enumerate(decoder.layers):\n",
    "            #print(\"i=\", i)\n",
    "            if i > 0 and i < len(_unet_skip_output_list):\n",
    "              #print(\"i >=1 and i < len(_unet_skip_output_list)\", i >1 and i < len(_unet_skip_output_list))\n",
    "              #print(\"i \", i,\", -1-i \", -1-i)\n",
    "              f._unet_skip_input = _unet_skip_output_list[-1-i]\n",
    "              #print(\"f._unet_skip_input.shape\", f._unet_skip_input.shape)\n",
    "        y = decoder(z)\n",
    "          #print(\"self.decoder(z).shape \", y.shape)\n",
    "        #y = y.transpose(1, 2) # (batch, lag, d_model)\n",
    "        #print(\" y.transpose(1, 2).shape \", y.shape)\n",
    "        #y = y + seq_last\n",
    "        #y = F.relu(y+x)\n",
    "        #y = F.relu(y)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KUNet(nn.Module):\n",
    "    def __init__(self, input_dim=1, input_len=8, \n",
    "                 n_width=[1], n_height=[8, 8], \n",
    "                 latent_dim=128, latent_len=1, \n",
    "                 output_dim=1, output_len=8, \n",
    "                 hidden_dim=[128]*3, kernel_hidden_layer=[1, 1, 1],\n",
    "                 kernel=[nn.Linear]*3, verbose=False, \n",
    "                 params={\"skip_conn\":True, \n",
    "                         \"unet_skip_mode\":\"concat\",\n",
    "                         \"unet_skip_concat\":False,\n",
    "\n",
    "                         \"inverse_norm\":False,\n",
    "                         \"mean_norm\":False,\n",
    "                         \"chanel_independent\":False,\n",
    "                         \"residual\":False, }):\n",
    "                 \n",
    "        super(KUNet, self).__init__()\n",
    "\n",
    "        self.inverse_norm = False\n",
    "        self.mean_norm = False\n",
    "        self.chanel_independent = False\n",
    "        self.residual = False\n",
    "\n",
    "        update_params(self, params)\n",
    "\n",
    "        if isinstance(n_width, int):\n",
    "           n_width = [n_width]\n",
    "        if isinstance(n_height, int):\n",
    "           n_height = [n_height]\n",
    "\n",
    "        n_enc_layers = 1 + len(n_width) + len(n_height) - (1 if np.prod(n_width) == 1 else 0) - (1 if np.prod(n_height) == 1 else 0)\n",
    "        if isinstance(hidden_dim, int):\n",
    "           hidden_dim = [hidden_dim] * n_enc_layers\n",
    "        if isinstance(kernel_hidden_layer, str):\n",
    "           kernel_hidden_layer = [int(i) for i in kernel_hidden_layer]\n",
    "        if not isinstance(kernel, list):\n",
    "           kernel = [nn.Linear if i == 0 else kernel for i in kernel_hidden_layer]\n",
    "\n",
    "        self.model = KUNetEncoderDecoder(input_dim=input_dim, input_len=input_len, \n",
    "                                        n_width=n_width, n_height=n_height, \n",
    "                                        latent_dim=latent_dim, latent_len=latent_len,\n",
    "                                        output_dim=output_dim, output_len=output_len, \n",
    "                                        hidden_dim=hidden_dim, \n",
    "                                        kernel=kernel, kernel_hidden_layer=kernel_hidden_layer,\n",
    "                                        verbose=verbose, params=params)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, L, M = x.shape\n",
    "        if self.residual:\n",
    "          res = x\n",
    "        # Instance normalization - pahse 1\n",
    "        if self.inverse_norm:\n",
    "          seq_std, seq_mean = torch.std_mean(x, dim=1, keepdim=True)\n",
    "          if self.mean_norm : # noly use mean normalisation\n",
    "            seq_std = 1\n",
    "          x = (x - seq_mean) / (seq_std + 0.000001)\n",
    "\n",
    "        # Chanel Independent - pahse 1\n",
    "        if self.chanel_independent :\n",
    "            x = x.transpose(2, 1)\n",
    "            x = x.reshape(B * M, L, 1)  # Reshape the input to (batch_size, input_len)\n",
    "        \n",
    "        output = self.model(x)\n",
    "\n",
    "        # Chanel Independent - pahse 2\n",
    "        if self.chanel_independent :\n",
    "            output = output.reshape(B, M, L)  # Reshape the input to (batch_size, input_len)\n",
    "            output = output.transpose(2, 1)\n",
    "\n",
    "        # Instance normalization - pahse 2\n",
    "        if self.inverse_norm:\n",
    "          output = output * (seq_std + 0.000001)   + seq_mean\n",
    "\n",
    "        if self.residual:\n",
    "          output += res\n",
    "        return output\n",
    "\n",
    "    def set_latent_conditions(self, latent):\n",
    "        self.model.latent_condition = latent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.lag_list [8, 8, 8]\n",
      "hidden_dim [128, 128, 128]\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "kernel  <class '__main__.LSTM'> is a Kernel\n",
      "kernel  <class '__main__.Transformer'> is a Kernel\n",
      "kernel  <class '__main__.Transformer'> is a Kernel\n",
      "kernel  <class '__main__.LSTM'> is a Kernel\n",
      "kernel  <class '__main__.Linear'> is a Kernel\n",
      "KUNet(\n",
      "  (model): KUNetEncoderDecoder(\n",
      "    (encoder): KUNetEncoder(\n",
      "      (layers): Sequential(\n",
      "        (0): KernelWrapper(\n",
      "          (kernel): Linear(\n",
      "            (layers): Sequential(\n",
      "              (0): Linear(in_features=1024, out_features=576, bias=True)\n",
      "              (1): Tanh()\n",
      "              (2): Dropout(p=0.05, inplace=False)\n",
      "              (3): Linear(in_features=576, out_features=128, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): KernelWrapper(\n",
      "          (kernel): LSTM(\n",
      "            (linear_projection_in): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (linear_projection_out): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (lstm): LSTM(128, 128, batch_first=True, dropout=0.05)\n",
      "          )\n",
      "        )\n",
      "        (2): KernelWrapper(\n",
      "          (kernel): Transformer(\n",
      "            (linear_projection_in): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (linear_projection_out): Linear(in_features=1024, out_features=128, bias=True)\n",
      "            (attention): Sequential(\n",
      "              (0): AttentionBlock(\n",
      "                (multi_head_attention): MultiHeadAttention(\n",
      "                  (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "                )\n",
      "                (relu): LeakyReLU(negative_slope=0.01)\n",
      "                (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (decoder): KUNetDecoder(\n",
      "      (layers): Sequential(\n",
      "        (0): KernelWrapper(\n",
      "          (kernel): Transformer(\n",
      "            (linear_projection_in): Linear(in_features=128, out_features=1024, bias=True)\n",
      "            (linear_projection_out): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "            (attention): Sequential(\n",
      "              (0): AttentionBlock(\n",
      "                (multi_head_attention): MultiHeadAttention(\n",
      "                  (Wq): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (Wk): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (Wv): Linear(in_features=128, out_features=128, bias=True)\n",
      "                  (fc): Linear(in_features=128, out_features=128, bias=True)\n",
      "                )\n",
      "                (relu): LeakyReLU(negative_slope=0.01)\n",
      "                (linear): Linear(in_features=128, out_features=128, bias=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): KernelWrapper(\n",
      "          (kernel): LSTM(\n",
      "            (linear_projection_in): Linear(in_features=256, out_features=2048, bias=True)\n",
      "            (linear_projection_out): Linear(in_features=2048, out_features=1024, bias=True)\n",
      "            (lstm): LSTM(256, 256, batch_first=True, dropout=0.05)\n",
      "          )\n",
      "        )\n",
      "        (2): KernelWrapper(\n",
      "          (kernel): Linear(\n",
      "            (layers): Sequential(\n",
      "              (0): Linear(in_features=256, out_features=640, bias=True)\n",
      "              (1): Tanh()\n",
      "              (2): Dropout(p=0.05, inplace=False)\n",
      "              (3): Linear(in_features=640, out_features=1024, bias=True)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "kun = KUNet(input_dim=128, input_len=8, \n",
    "                 n_width=[1], n_height=[8, 8], \n",
    "                 latent_dim=128, latent_len=1, \n",
    "                 output_dim=128, output_len=8, \n",
    "                 hidden_dim=[128]*3, \n",
    "                 kernel=[Linear, LSTM, Transformer], kernel_hidden_layer=[1, 1, 1],\n",
    "                 verbose=True, params={\"skip_conn\":True, \n",
    "                         \"unet_skip_mode\":\"concat\",\n",
    "                         \"unet_skip_concat\":True,\n",
    "\n",
    "                         \"inverse_norm\":False,\n",
    "                         \"mean_norm\":False,\n",
    "                         \"chanel_independent\":False,\n",
    "                         \"residual\":False, })\n",
    "print(kun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-KUN-Encoder.forward(x) Input x.shape:  torch.Size([13, 512, 128])\n",
      "-KUN-Encoder.forward(x) x = x.reshape((-1,) + tuple(self.n_width) + (self.input_dim,) + tuple(self.n_height) + (1,) +(self.input_len,)).shape  torch.Size([13, 64, 8, 1, 1, 128])\n",
      "-KUN-Encoder.forward(x)  x = x.transpose(1+len(self.n_width), 1+len(self.n_width)+len(self.n_height)+1).shape  torch.Size([13, 1, 64, 8, 128])\n",
      "-KUN-Encoder.forward(x) x = x.reshape((-1, self.input_len, self.input_dim)).shape  torch.Size([832, 8, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([832, 8, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([832, 8, 128])\n",
      "after reshape - > x.shape torch.Size([832, 8, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([832, 8, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([832, 1, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([832, 1, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([832, 1, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([832, 1, 128])\n",
      "after reshape - > x.shape torch.Size([104, 8, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([104, 8, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([104, 1, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([104, 1, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([104, 1, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([104, 1, 128])\n",
      "after reshape - > x.shape torch.Size([13, 8, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([13, 8, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([13, 1, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([13, 1, 128])\n",
      "-KUN-Encoder.forward(x) self.layers(x).shape  torch.Size([13, 1, 128])\n",
      "-KUN-Encoder.forward(x) x = x.reshape((-1, self.output_len, self.output_dim)).shape  torch.Size([13, 1, 128])\n",
      "-KUN-Decoder.forward(x) start x.shape  torch.Size([13, 1, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([13, 1, 128])\n",
      "---train: False\n",
      "---_unet_skip_input None\n",
      "reshape - > x.shape torch.Size([13, 1, 128])\n",
      "after reshape - > x.shape torch.Size([13, 1, 128])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([13, 1, 128])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([13, 8, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([13, 8, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([13, 8, 128])\n",
      "---train: False\n",
      "---_unet_skip_input.shape torch.Size([104, 1, 128])\n",
      "self.transpose and self._unet_skip_input\n",
      "--x.shape torch.Size([13, 8, 128])\n",
      "self.unet_skip_concat, x.shape True torch.Size([13, 8, 128])\n",
      "reshape - > x.shape torch.Size([13, 8, 256])\n",
      "after reshape - > x.shape torch.Size([104, 1, 256])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([104, 1, 256])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([104, 8, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([104, 8, 128])\n",
      "---KernelWrapper.forward(x) Input x.shape: torch.Size([104, 8, 128])\n",
      "---train: False\n",
      "---_unet_skip_input.shape torch.Size([832, 1, 128])\n",
      "self.transpose and self._unet_skip_input\n",
      "--x.shape torch.Size([104, 8, 128])\n",
      "self.unet_skip_concat, x.shape True torch.Size([104, 8, 128])\n",
      "reshape - > x.shape torch.Size([104, 8, 256])\n",
      "after reshape - > x.shape torch.Size([832, 1, 256])\n",
      "---KernelWrapper.f(x) Input x.shape:  torch.Size([832, 1, 256])\n",
      "---KernelWrapper.f(x) Output x.shape:  torch.Size([832, 8, 128])\n",
      "after x = self.f(x) - > x.shape torch.Size([832, 8, 128])\n",
      "-KUN-Decoder.forward(x) self.layers(x).shape  torch.Size([832, 8, 128])\n",
      "-KUN-Decoder.forward(x) x.reshape((-1,)+ tuple(self.n_width) + (1,) + tuple(self.n_height) + (self.output_dim,)  + (self.output_len,)).reshape  torch.Size([13, 1, 1, 64, 8, 128])\n",
      "-KUN-Decoder.forward(x) x.transpose(2+len(self.n_width), 2+len(self.n_width)+2+len(self.n_height)).shape  torch.Size([13, 64, 1, 1, 8, 128])\n",
      "-KUN-Decoder.forward(x) x.reshape((x_shape[0], self.total_width, self.total_height*self.input_len)).shape  torch.Size([13, 512, 128])\n",
      "torch.Size([13, 512, 128])\n"
     ]
    }
   ],
   "source": [
    "x = kun(torch.rand((13,512,128)))\n",
    "print(x.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
